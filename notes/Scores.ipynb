{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8rhOo64/HBcthfhxflWic",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R0bk/ml_replications/blob/main/notes/Scores.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEIE1x-BNqdz"
      },
      "source": [
        "#Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cctv5hFNvGO"
      },
      "source": [
        "A score is the graident of the probability density w.r.t. the input dimensions (not w.r.t. model parameters of a model trying to replciate the prob density)\n",
        "\n",
        "\n",
        "Why work with scores?\n",
        "One issue with PDFs is that they are normalised, as in the integral has always to be 1, but for scores this doesn't have to be true so instead they can be an arbitrary function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly2G9-OkR7jj"
      },
      "source": [
        "##EBMs\n",
        "An example of using this would be with a deep energy based model (EBM).\n",
        "\n",
        "Since we want a flexiable model that can map any function we can use a deep neural network (DNN) that takes a sample $x$ and maps it to a real number\n",
        "\n",
        "$f_Œ∏(x)\\in‚Ñù$\n",
        "\n",
        "Since we know the probability density has to be non-negitive we can take the exponential of the negativive of the pd. But to be a valid PDF we need to ensure that the $\\int_a^b p_\\theta(x) dx=1$. So to do this we need to divide by a normalizing constant, this gives us the model.\n",
        "\n",
        "$p_Œ∏(x)=\\frac{e^{-f_\\theta(x)}}{Z_Œ∏}$\n",
        "\n",
        "We can plug in any neural network we want into this model to find the PDF but the problem is that the normalizer $Z_\\theta$ may be intractable or very hard to calculate. You can see this if we try to learn $\\theta$ by maximum likelihood.\n",
        "\n",
        "$ùîº_{p_{data}}[-log\\;p_\\theta(x)] = ùîº_{p_{data}}[log\\;f_\\theta(x)-log\\;Z_\\theta]$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekl95vsMXA64"
      },
      "source": [
        "## Score based\n",
        "If we take the gradient of the MLE function above w.r.t. $x$ we get the below.\n",
        "\n",
        "$\\nabla_xlog\\;p_\\theta(x)=-\\nabla_x\\;f_\\theta(x)-\\nabla_xlog\\;Z_\\theta$\n",
        "\n",
        "But we can see that the last term w.r.t. $x$ will actually be 0 and we don't need to comute it giving us a tractable function\n",
        "\n",
        "$\\nabla_xlog\\;p_\\theta(x)=-\\nabla_x\\;f_\\theta(x)$\n",
        "\n",
        "So if we can build a model that can attempt to learn in the vector field of graidents instead of in the probability density space we can avoid the intractable computation all togther"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LdG63h7Y8V1"
      },
      "source": [
        "##Score Estimation\n",
        "So how do we learn actually given the data, well given iid samples\n",
        "\n",
        "$\\{x_1, x_2, ... x_N\\} \\stackrel{i.i.d.}{\\sim} p_{data}(x)=p(x)$\n",
        "\n",
        "And given the task of estimating the score \n",
        "\n",
        "$\\nabla_xlog\\;p_\\theta(x)$\n",
        "\n",
        "And given the score model (a vector valued function)\n",
        "\n",
        "$s_\\theta(x): ‚Ñù^D \\to ‚Ñù^D$\n",
        "\n",
        "We need to figure out a way to compare two vector fields of score, e.g. compare $\\nabla_xlog\\;p_\\theta(x)$ and $s_\\theta(x)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELF8KJV7bIAQ"
      },
      "source": [
        "## Score Matching\n",
        "We can take essentially a l2 norm between the two vector fields as\n",
        "\n",
        "$\\frac{1}{2}ùîº_{p(x)}[||\\nabla_xlog\\;p(x)-s_\\theta(x)||_2^2]$\n",
        "\n",
        "The l2 norm in this case is called the Fisher divergence\n",
        "\n",
        "The problem with this approach is that we don't know $\\nabla_xlog\\;p(x)$ as we don't know $p(x)$\n",
        "\n",
        "We can apply a trick under the assumption that the graidents disapear on the boundary and do integration by parts to get\n",
        "\n",
        "$ùîº_{p(x)}[||\\frac{1}{2}s_\\theta(x)||_2^2 + trace(\\;\\nabla_xs_\\theta(x)\\;)]$\n",
        "\n",
        "Where $\\nabla_xs_\\theta(x)$ is the Jacobian of $s_\\theta(x)$\n",
        "\n",
        "This is called score matching (full proof is in 2005 paper).\n",
        "\n",
        "With data we can write this objective as\n",
        "\n",
        "$\\frac{1}{N}\\sum_{i=1}^N[||\\frac{1}{2}s_\\theta(x_i)||_2^2 + trace(\\;\\nabla_xs_\\theta(x_i)\\;)]$\n",
        "\n",
        "for\n",
        "\n",
        "$\\{x_1, x_2, ... x_N\\} \\stackrel{i.i.d.}{\\sim}p(x)$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAVZb2LqdqP9"
      },
      "source": [
        "### Score matching example\n",
        "We create a DNN that will be used as $s_\\theta(x)$. Now we need to calculate  $\\frac{1}{N}\\sum_{i=1}^N[||\\frac{1}{2}s_\\theta(x_i)||_2^2 + trace(\\;\\nabla_xs_\\theta(x_i)\\;)]$ in order to provide updates to the network. We can do this in two parts\n",
        "\n",
        "First we calculate $||\\frac{1}{2}s_\\theta(x)||_2^2$ by simply doing a forward pass of the network and then taking the norm but to calculate $trace(\\;\\nabla_xs_\\theta(x_i)\\;)$ we need to first calculate the jacobian of the network.\n",
        "\n",
        "The jacobian $\\nabla_xs_\\theta(x_i)=\n",
        "\\begin{bmatrix}\n",
        "  \\frac{\\partial s_{\\theta,1}(x)}{\\partial x_1} & \n",
        "    \\frac{\\partial s_{\\theta,1}(x)}{\\partial x_2} & \n",
        "    \\frac{\\partial s_{\\theta,1}(x)}{\\partial x_3} \\\\[1ex]\n",
        "  \\frac{\\partial s_{\\theta,2}(x)}{\\partial x_1} & \n",
        "    \\frac{\\partial s_{\\theta,2}(x)}{\\partial x_2} & \n",
        "    \\frac{\\partial s_{\\theta,2}(x)}{\\partial x_3} \\\\[1ex]\n",
        "  \\frac{\\partial s_{\\theta,3}(x)}{\\partial x_1} & \n",
        "    \\frac{\\partial s_{\\theta,3}(x)}{\\partial x_2} & \n",
        "    \\frac{\\partial s_{\\theta,3}(x)}{\\partial x_3}\n",
        "\\end{bmatrix}$\n",
        "\n",
        "Requires us to take the deritive of each output of the network $s_{\\theta,output}(x)$ with respect to each input of the network. This means that to calculate the jacobian we are required to backprop once for every output in the network. (Note since we take the trace we only consider the diag entries) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCgh-1n1hCok"
      },
      "source": [
        "##Sliced score matching\n",
        "Since calculating the score match requires $O(N)$ parses where n is the number of data dimensions we want to find a way to do it faster. The idea with sliced score matching is to select a random direction and then project the vector field of the model output $\\nabla_x\\;f_\\theta(x)$ and the vector field of the data $\\nabla_xlog\\;p_\\theta(x)$ and project them onto a random $1d$ vector where we can more easily compute the divergence.\n",
        "\n",
        "This leads to sliced fisher divergence where we project every point $p$ onto a random direction $v$ giving us\n",
        "\n",
        "$\\frac{1}{2}ùîº_{p_v}ùîº_{p_{data}}[(v^T\\nabla_xlog\\;p_\\theta(x)-v^Tlog\\;p_{data}(x))^2]$\n",
        "\n",
        "but once again $p_{data}$ is intractable but just as before if we do the integration by parts trick we get out a divergence that looks like\n",
        "\n",
        "$ùîº_{p_v}ùîº_{p_{data}}[v^T\\nabla_x^2log\\;p_\\theta(x)v+\\frac{1}{2}(v^Tlog\\;p_\\theta(x))^2] + const$\n",
        "\n",
        "Now both parts of the comparison of function are fast! :)\n",
        "\n",
        "\n",
        "###Notes:\n",
        "When selecting the distribution to sample random directions from $p_v$ the distribution can have a big impact on trainning, ideally you want one that shows contrast between the data and the model gradients.\n",
        "\n",
        "You can also sample multiple projections per data sample for variance reduction if you want."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reg9lSpMkQII"
      },
      "source": [
        "##Sampling score matching (Langevin dynamics)\n",
        "Once we have a trained model that can predict the graident vector field of the data probability density $\\nabla_xlog\\;p_\\theta(x)$ we can now try to sample from it. First we initialise a random sample $\\hat{x}_0 \\sim \\pi(x)$ from any distribution of choice (similar to MCMC) then for step $t$ in range $T$ we can do the following process\n",
        "\n",
        "$\\hat{x}_t \\leftarrow \\hat{x}_{t-1}+\\frac{\\epsilon}{2}\\nabla_xlog\\;p_\\theta(\\hat{x}_{t-1}) + \\sqrt{\\epsilon}\\;z_t$\n",
        "\n",
        "where $z_t \\sim ùìù(0,I)$ is added to increase exploration. Essentially we are just choosing a random point and following the graident down with some minor exploration to try and not find local minimas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YflGL0bPnK9J"
      },
      "source": [
        "##Problems\n",
        "Projecting a high dimensional manifold onto low dimensional space can result in undefined gradients.\n",
        "\n",
        "Since we only learn gradients near data points (and lean the best gradients from the most common data points) much of the gradient landscape won't have learnt the true distribution and when attempting to sample the sample can get lost.\n",
        "\n",
        "Also since we sample from a distribution and follow that sample down the models graident landscape we are likely to end up in whatever minima that is most near by. This doesn't respect that some minimas may be more representitive of a mode in a dataset e.g. a dataset class vs others. So the average of the modes of Langevin dynamic samples will differ from the average of the modes of the true dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVd9VZKjqL_1"
      },
      "source": [
        "##Great Refrences\n",
        "\n",
        "https://ajolicoeur.wordpress.com/the-new-contender-to-gans-score-matching-with-langevin-sampling/\n",
        "\n",
        "https://yang-song.github.io/blog/2021/score/\n",
        "\n",
        "https://www.youtube.com/watch?v=8TcNXi3A5DI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw6qIleltlsE"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}