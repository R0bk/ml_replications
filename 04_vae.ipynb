{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXiNXgzafQy1Pu8D0HEUOv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R0bk/ml_replications/blob/main/04_vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deDJDu0jEdnW"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_tKp9TGGKuo"
      },
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tXX_TBcGSRH",
        "outputId": "f9867e5d-4888-433a-edf5-2cd221a80294"
      },
      "source": [
        "batch_size = 128\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
        "    print(\"Shape of y: \", y.shape, y.dtype)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]:  torch.Size([128, 1, 28, 28])\n",
            "Shape of y:  torch.Size([128]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qzLAYPHGYUH",
        "outputId": "6ef541da-1a81-467c-9e1b-bf77ad30e0c6"
      },
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "\n",
        "    self.encoder = nn.Sequential(\n",
        "        nn.Linear(28*28, 400),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(400, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64, 40),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.decoder = nn.Sequential(\n",
        "        nn.Linear(20, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64, 400),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(400, 28*28),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def sample(self, x):\n",
        "    mu = x[:, 0, :]\n",
        "    if self.training:\n",
        "      stds = x[:, 1, :]\n",
        "\n",
        "      eps = torch.normal(0., 1., stds.shape).to(device)\n",
        "      x = stds.exp().mul(eps).add(mu)\n",
        "      \n",
        "      return x, mu, stds\n",
        "    return mu, None, None\n",
        "    \n",
        "\n",
        "  def forward(self, x, batch_size):\n",
        "    x = self.flatten(x)\n",
        "    x = self.encoder(x)\n",
        "    x, mu, stds = self.sample(torch.reshape(x, (batch_size, 2, 20)))\n",
        "    x = self.decoder(x)\n",
        "    return x, mu, stds\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (encoder): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=400, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=400, out_features=64, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=64, out_features=40, bias=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            "  (decoder): Sequential(\n",
            "    (0): Linear(in_features=20, out_features=64, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=64, out_features=400, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=400, out_features=784, bias=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvw8fCc9uLTc",
        "outputId": "0696d365-090f-4682-dba7-b85da840d647"
      },
      "source": [
        "mse = nn.MSELoss(size_average=False)\n",
        "def loss_fn(y, pred, means, stds):\n",
        "\n",
        "  loss = mse(y, pred)\n",
        "  kld = means.pow(2).add(1).div(stds.exp().pow(2)).sub(1).add(stds.mul(2))\n",
        "  kld = kld.mul(0.5).sum()\n",
        "  return loss.add(kld), kld"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8mf3Cn44jmS"
      },
      "source": [
        "optimiser = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OLZjO6xH1iX"
      },
      "source": [
        "def train(dataloader, model, loss_fn, optimiser):\n",
        "  size = len(train_dataloader.dataset)\n",
        "\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    # print('hi')\n",
        "    pred, means, stds = model(X, len(X))\n",
        "    # print(pred.shape)\n",
        "    # print(X.squeeze().flatten(1).shape)\n",
        "    loss, kl_loss = loss_fn(X.squeeze().flatten(1), pred, means, stds)\n",
        "    \n",
        "\n",
        "    optimiser.zero_grad()\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), batch * len(X)\n",
        "      print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\", kl_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpM50IVDIl0A"
      },
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_d-pp-4IzHv",
        "outputId": "c8640364-7105-4d8e-99cb-08b26fa064a0"
      },
      "source": [
        "epochs = 40\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimiser)\n",
        "    # test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 18773.445312  [    0/60000] tensor(11.3471, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 7575.714844  [12800/60000] tensor(686.3396, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 6618.272949  [25600/60000] tensor(812.8885, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 5534.042480  [38400/60000] tensor(806.9263, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 5589.187988  [51200/60000] tensor(881.5921, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 5684.200195  [    0/60000] tensor(781.9841, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 5463.739258  [12800/60000] tensor(892.3912, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 5461.671875  [25600/60000] tensor(851.7177, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 5205.003906  [38400/60000] tensor(817.7628, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4961.550293  [51200/60000] tensor(905.8105, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 5191.304688  [    0/60000] tensor(757.7585, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 5156.305664  [12800/60000] tensor(848.3215, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 5053.154297  [25600/60000] tensor(836.8806, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4796.428223  [38400/60000] tensor(788.4502, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 5024.434570  [51200/60000] tensor(827.4607, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 5011.006836  [    0/60000] tensor(848.7161, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4775.338867  [12800/60000] tensor(834.9377, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4884.886230  [25600/60000] tensor(822.3449, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4590.878906  [38400/60000] tensor(839.1827, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4546.869141  [51200/60000] tensor(857.4150, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 4836.965820  [    0/60000] tensor(907.2181, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4720.432129  [12800/60000] tensor(867.4086, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4687.908691  [25600/60000] tensor(907.9280, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4493.957031  [38400/60000] tensor(842.7798, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4418.310547  [51200/60000] tensor(721.6602, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 4830.090820  [    0/60000] tensor(878.7979, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4606.077637  [12800/60000] tensor(935.5830, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4583.251953  [25600/60000] tensor(851.3040, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4554.088379  [38400/60000] tensor(811.3627, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4459.958984  [51200/60000] tensor(865.1243, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 4619.890625  [    0/60000] tensor(832.8263, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4389.160156  [12800/60000] tensor(883.1821, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4448.803223  [25600/60000] tensor(864.3132, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4246.956055  [38400/60000] tensor(757.6819, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4178.711426  [51200/60000] tensor(804.6955, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 4371.519531  [    0/60000] tensor(815.8890, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4399.511230  [12800/60000] tensor(979.6231, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4700.923340  [25600/60000] tensor(920.8325, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4107.391602  [38400/60000] tensor(794.7938, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4304.497559  [51200/60000] tensor(882.6676, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 4483.689941  [    0/60000] tensor(876.0670, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4254.375000  [12800/60000] tensor(951.9380, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4498.122070  [25600/60000] tensor(881.4636, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4349.427734  [38400/60000] tensor(826.2529, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4317.809570  [51200/60000] tensor(797.2951, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 4413.342773  [    0/60000] tensor(824.3032, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4420.555176  [12800/60000] tensor(958.4500, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4476.465820  [25600/60000] tensor(915.8988, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4193.436523  [38400/60000] tensor(867.4608, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4394.463379  [51200/60000] tensor(805.8134, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 4525.732910  [    0/60000] tensor(912.3165, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4260.809082  [12800/60000] tensor(919.2057, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4394.535645  [25600/60000] tensor(910.7032, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4129.160156  [38400/60000] tensor(869.7812, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4124.499512  [51200/60000] tensor(920.5033, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 4559.179688  [    0/60000] tensor(928.2303, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4350.214355  [12800/60000] tensor(891.9544, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4381.473145  [25600/60000] tensor(957.9227, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4115.644043  [38400/60000] tensor(890.6963, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4212.339844  [51200/60000] tensor(876.1694, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 4236.263672  [    0/60000] tensor(902.5605, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4594.924805  [12800/60000] tensor(1138.1770, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4317.725098  [25600/60000] tensor(942.9380, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4112.246582  [38400/60000] tensor(884.8266, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4326.829102  [51200/60000] tensor(788.3536, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 4692.980957  [    0/60000] tensor(837.8368, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4076.886230  [12800/60000] tensor(959.3507, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4169.453613  [25600/60000] tensor(937.9066, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4131.315430  [38400/60000] tensor(908.7435, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4037.415283  [51200/60000] tensor(885.1663, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 4263.332031  [    0/60000] tensor(906.6340, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4111.449219  [12800/60000] tensor(912.5598, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4491.740234  [25600/60000] tensor(1032.4703, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4088.199219  [38400/60000] tensor(957.7125, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4197.584961  [51200/60000] tensor(910.0566, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 4390.596191  [    0/60000] tensor(972.1367, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4190.482910  [12800/60000] tensor(997.1270, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4384.968262  [25600/60000] tensor(873.1237, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3909.448975  [38400/60000] tensor(886.6746, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3996.955078  [51200/60000] tensor(796.6418, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 4191.245605  [    0/60000] tensor(906.2526, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3958.323486  [12800/60000] tensor(976.7575, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4053.914307  [25600/60000] tensor(910.6252, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4097.877930  [38400/60000] tensor(917.0989, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3947.261963  [51200/60000] tensor(816.1380, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 4311.209473  [    0/60000] tensor(899.6818, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4206.039551  [12800/60000] tensor(982.0426, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4287.041504  [25600/60000] tensor(963.7760, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3972.565430  [38400/60000] tensor(926.1519, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3949.944824  [51200/60000] tensor(837.9467, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 4247.675781  [    0/60000] tensor(872.2413, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4107.041992  [12800/60000] tensor(1032.5303, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4270.025391  [25600/60000] tensor(959.4421, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3992.968994  [38400/60000] tensor(855.5269, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3988.529297  [51200/60000] tensor(874.2413, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 4327.889648  [    0/60000] tensor(848.7327, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4023.597900  [12800/60000] tensor(1099.9846, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4417.468750  [25600/60000] tensor(912.2112, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3952.353027  [38400/60000] tensor(865.6857, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4053.821777  [51200/60000] tensor(922.3727, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 4268.591797  [    0/60000] tensor(889.6013, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4096.426758  [12800/60000] tensor(1034.1472, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4193.943359  [25600/60000] tensor(960.3118, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4029.934082  [38400/60000] tensor(882.6877, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4000.614746  [51200/60000] tensor(776.7802, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 4347.456055  [    0/60000] tensor(897.1433, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4097.959473  [12800/60000] tensor(960.4541, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3973.398926  [25600/60000] tensor(936.1447, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4139.846680  [38400/60000] tensor(883.4229, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3973.741699  [51200/60000] tensor(848.0830, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 4363.630371  [    0/60000] tensor(870.3561, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4220.859863  [12800/60000] tensor(1054.3202, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4227.246094  [25600/60000] tensor(953.1540, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4117.770996  [38400/60000] tensor(924.0104, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4146.013184  [51200/60000] tensor(817.8483, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 4246.773438  [    0/60000] tensor(900.3317, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3934.333984  [12800/60000] tensor(967.6969, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4283.262695  [25600/60000] tensor(939.1545, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3963.052979  [38400/60000] tensor(919.4202, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4028.377441  [51200/60000] tensor(847.4854, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 4174.889160  [    0/60000] tensor(820.4325, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4004.527100  [12800/60000] tensor(965.8984, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4156.083008  [25600/60000] tensor(1018.7356, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3820.325195  [38400/60000] tensor(939.0988, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3923.322266  [51200/60000] tensor(849.4844, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 4043.472656  [    0/60000] tensor(898.7438, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4167.596680  [12800/60000] tensor(902.4482, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4183.115234  [25600/60000] tensor(919.0134, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3990.364502  [38400/60000] tensor(992.5342, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3822.537598  [51200/60000] tensor(835.0870, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 4794.085449  [    0/60000] tensor(846.6788, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3921.311035  [12800/60000] tensor(982.8077, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4386.027832  [25600/60000] tensor(929.0694, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4019.398682  [38400/60000] tensor(839.8860, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4034.944336  [51200/60000] tensor(844.3519, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 4194.652344  [    0/60000] tensor(911.9628, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4001.822510  [12800/60000] tensor(1028.6917, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4221.018555  [25600/60000] tensor(1061.2067, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3880.528809  [38400/60000] tensor(935.6669, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3871.304199  [51200/60000] tensor(836.5690, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 3970.901855  [    0/60000] tensor(921.8257, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3901.663330  [12800/60000] tensor(979.4004, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4024.300293  [25600/60000] tensor(973.0648, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3904.826660  [38400/60000] tensor(974.6959, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3939.108154  [51200/60000] tensor(844.8953, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 4007.747070  [    0/60000] tensor(932.4331, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3976.859131  [12800/60000] tensor(987.7014, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4142.999512  [25600/60000] tensor(915.7330, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4073.934082  [38400/60000] tensor(879.0983, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3943.955566  [51200/60000] tensor(843.8972, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 4093.338867  [    0/60000] tensor(867.2383, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4027.147217  [12800/60000] tensor(948.7771, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4078.486084  [25600/60000] tensor(929.5872, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4074.833008  [38400/60000] tensor(899.3394, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4028.940430  [51200/60000] tensor(793.1642, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 4030.095459  [    0/60000] tensor(863.8269, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3971.856934  [12800/60000] tensor(967.7622, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3944.115234  [25600/60000] tensor(904.7568, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3855.204834  [38400/60000] tensor(872.1770, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3802.011963  [51200/60000] tensor(818.6805, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 4078.424561  [    0/60000] tensor(897.2566, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3999.553711  [12800/60000] tensor(912.1035, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4071.022949  [25600/60000] tensor(952.0684, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3989.834473  [38400/60000] tensor(884.9974, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3905.017090  [51200/60000] tensor(878.6045, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 4115.917969  [    0/60000] tensor(847.8683, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3865.371826  [12800/60000] tensor(998.6685, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4067.711914  [25600/60000] tensor(1022.9762, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3940.181396  [38400/60000] tensor(888.7224, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3679.974609  [51200/60000] tensor(849.0670, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 4083.437256  [    0/60000] tensor(885.4495, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3985.429688  [12800/60000] tensor(946.8781, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4113.742188  [25600/60000] tensor(1002.1962, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3796.472900  [38400/60000] tensor(889.4084, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3936.294434  [51200/60000] tensor(777.9113, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 4081.538574  [    0/60000] tensor(904.1479, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3869.993652  [12800/60000] tensor(850.2167, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4124.568848  [25600/60000] tensor(990.3846, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3942.564941  [38400/60000] tensor(847.0972, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3960.720703  [51200/60000] tensor(841.8635, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 4057.469971  [    0/60000] tensor(893.7952, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4060.843750  [12800/60000] tensor(930.2700, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4104.113281  [25600/60000] tensor(931.8474, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3937.114258  [38400/60000] tensor(940.9127, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3749.835449  [51200/60000] tensor(819.6554, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 4157.901367  [    0/60000] tensor(927.4915, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3801.831055  [12800/60000] tensor(962.0248, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4064.443848  [25600/60000] tensor(906.0181, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3909.835205  [38400/60000] tensor(892.3157, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3815.292969  [51200/60000] tensor(882.6949, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 3976.877441  [    0/60000] tensor(871.7367, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3966.356689  [12800/60000] tensor(926.9523, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3975.526855  [25600/60000] tensor(973.9282, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3885.843262  [38400/60000] tensor(848.0917, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3952.784180  [51200/60000] tensor(802.3450, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 4039.767578  [    0/60000] tensor(948.8317, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3929.057373  [12800/60000] tensor(995.3934, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 4033.851318  [25600/60000] tensor(972.7131, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3952.456543  [38400/60000] tensor(905.3422, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "loss: 3954.358643  [51200/60000] tensor(819.6548, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxqyxNgVI3yP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "0d1f757d-ad22-4d47-fa87-f03b80980d8c"
      },
      "source": [
        "def plot(dataloader, model, loss_fn):\n",
        "    i = 0\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            i+=1\n",
        "            print(X.shape)\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred, means, stds = model(X, len(X))\n",
        "            print(pred.shape)\n",
        "            plt.figure()\n",
        "            plt.imshow(  X.cpu()[0].squeeze()  )\n",
        "            plt.figure()\n",
        "            plt.imshow(  pred.cpu().unflatten(1, torch.Size([28, 28]))[0]  )\n",
        "            if i == 10:\n",
        "              break\n",
        "plot(train_dataloader, model, loss_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 1, 28, 28])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-501-cff3e8e8430f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m               \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-501-cff3e8e8430f>\u001b[0m in \u001b[0;36mplot\u001b[0;34m(dataloader, model, loss_fn)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-495-3ad1487b861e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, batch_size)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgqmLVufRjKy"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}